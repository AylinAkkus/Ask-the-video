import { Box, Stack, Text, TextInput, Button, ScrollArea, Paper, Loader, Alert } from '@mantine/core'
import { useEffect, useState, useRef } from 'react'
import { WorkerMessageTypes } from '../../background/types'
import { TranscriptResult } from '../../contentScript/youtubeTranscript'
import { getChatResponse, ChatMessage as LLMChatMessage } from '../../utils/llm'
import { parseTimestampLinks } from '../../utils/timestampUtils'

interface ChatMessage {
  role: 'user' | 'assistant'
  content: string
  timestamp: number
}

interface VideoInfo {
  videoId: string
  language: string
  isAutoGenerated: boolean
  videoTitle: string | null
  videoThumbnail: string | null
  videoDescription: string | null
  videoUploadDate: string | null
  videoChannelName: string | null
}

const VideoChat = () => {
  const [transcript, setTranscript] = useState<TranscriptResult | null>(null)
  const [videoInfo, setVideoInfo] = useState<VideoInfo | null>(null)
  const [isLoading, setIsLoading] = useState(true)
  const [error, setError] = useState<string | null>(null)
  const [chatHistory, setChatHistory] = useState<ChatMessage[]>([])
  const [question, setQuestion] = useState('')
  const [isProcessing, setIsProcessing] = useState(false)
  const scrollAreaRef = useRef<HTMLDivElement>(null)

  useEffect(() => {
    // Listen for transcript loaded messages
    const handleMessage = (message: { type: string; payload?: any }) => {
      if (message.type === WorkerMessageTypes.transcriptLoaded) {
        const data: TranscriptResult = message.payload
        console.log('ðŸ“‹ Transcript received in side panel:', {
          videoId: data.videoId,
          title: data.metadata?.title,
          channel: data.metadata?.channelName,
          segmentCount: data.transcript?.length,
        })
        
        // Check if this is a new video
        const isNewVideo = transcript?.videoId !== data.videoId
        
        if (isNewVideo) {
          console.log('ðŸ”„ NEW VIDEO DETECTED! Old:', transcript?.videoId, 'New:', data.videoId)
          console.log('ðŸ§¹ Clearing chat history for new video')
          // Clear chat history FIRST before setting new data
          setChatHistory([])
        }
        
        setTranscript(data)
        setIsLoading(false)
        setError(null)
        
        if (data.videoId) {
          const newVideoInfo = {
            videoId: data.videoId,
            language: data.language || 'unknown',
            isAutoGenerated: data.isAutoGenerated || false,
            videoTitle: data.metadata?.title || data.videoTitle || null,
            videoThumbnail: data.metadata?.videoThumbnail || data.videoThumbnail || null,
            videoDescription: data.metadata?.description || null,
            videoUploadDate: data.metadata?.uploadDate || null,
            videoChannelName: data.metadata?.channelName || null,
          }
          console.log('ðŸŽ¥ Setting NEW video info:', {
            videoId: newVideoInfo.videoId,
            title: newVideoInfo.videoTitle,
            channel: newVideoInfo.videoChannelName,
            description: newVideoInfo.videoDescription?.substring(0, 50),
          })
          setVideoInfo(newVideoInfo)
        }
      } else if (message.type === WorkerMessageTypes.transcriptError) {
        console.error('âŒ Transcript error received:', message.payload)
        setError(message.payload.error || 'Failed to load transcript')
        setIsLoading(false)
      }
    }

    chrome.runtime.onMessage.addListener(handleMessage)

    // Request current transcript on mount
    chrome.runtime.sendMessage({ type: WorkerMessageTypes.getTranscript }, (response) => {
      if (response?.success && response.data) {
        setTranscript(response.data)
        setIsLoading(false)
        
        if (response.data.videoId) {
          setVideoInfo({
            videoId: response.data.videoId,
            language: response.data.language || 'unknown',
            isAutoGenerated: response.data.isAutoGenerated || false,
            videoTitle: response.data.metadata?.title || response.data.videoTitle || null,
            videoThumbnail: response.data.metadata?.videoThumbnail || response.data.videoThumbnail || null,
            videoDescription: response.data.metadata?.description || null,
            videoUploadDate: response.data.metadata?.uploadDate || null,
            videoChannelName: response.data.metadata?.channelName || null,
          })
        }
      } else {
        setIsLoading(false)
      }
    })

    return () => {
      chrome.runtime.onMessage.removeListener(handleMessage)
    }
  }, [transcript?.videoId])

  // Auto-scroll to bottom when new messages arrive
  useEffect(() => {
    if (scrollAreaRef.current) {
      const viewport = scrollAreaRef.current.querySelector('[data-radix-scroll-area-viewport]')
      if (viewport) {
        viewport.scrollTop = viewport.scrollHeight
      }
    }
  }, [chatHistory])

  const handleSendMessage = async () => {
    if (!question.trim() || !transcript?.transcript || isProcessing) {
      return
    }

    const userMessage: ChatMessage = {
      role: 'user',
      content: question.trim(),
      timestamp: Date.now(),
    }

    setChatHistory(prev => [...prev, userMessage])
    setQuestion('')
    setIsProcessing(true)

    try {
      // Log current video context
      console.log('ðŸ’¬ Sending chat message for video:', {
        videoId: transcript.videoId,
        title: transcript.metadata?.title,
        segmentCount: transcript.transcript.length,
      })

      // Convert chat history to LLM format
      const llmHistory: LLMChatMessage[] = chatHistory.map(msg => ({
        role: msg.role,
        content: msg.content,
      }))

      // Get response from LLM
      const response = await getChatResponse(
        transcript.transcript,
        llmHistory,
        userMessage.content,
        transcript.metadata
      )

      if (response.error) {
        throw new Error(response.errorMessage || 'Failed to get response')
      }

      const assistantMessage: ChatMessage = {
        role: 'assistant',
        content: response.response,
        timestamp: Date.now(),
      }

      setChatHistory(prev => [...prev, assistantMessage])

      // Notify background script
      chrome.runtime.sendMessage({
        type: WorkerMessageTypes.chatResponse,
        payload: { response: response.response },
      })
    } catch (error) {
      console.error('Error getting chat response:', error)
      const errorMessage: ChatMessage = {
        role: 'assistant',
        content: `Sorry, I encountered an error: ${error instanceof Error ? error.message : 'Unknown error'}`,
        timestamp: Date.now(),
      }
      setChatHistory(prev => [...prev, errorMessage])
    } finally {
      setIsProcessing(false)
    }
  }

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault()
      handleSendMessage()
    }
  }

  if (isLoading) {
    return (
      <Box p="md" style={{ display: 'flex', flexDirection: 'column', alignItems: 'center', gap: '1rem' }}>
        <Loader size="md" />
        <Text size="sm" c="dimmed">Loading transcript...</Text>
      </Box>
    )
  }

  if (error) {
    return (
      <Box p="md">
        <Alert color="red" title="Error">
          {error}
        </Alert>
        <Text size="sm" mt="md" c="dimmed">
          Make sure you're on a YouTube video page with available captions.
        </Text>
      </Box>
    )
  }

  if (!transcript?.transcript) {
    return (
      <Box p="md">
        <Alert color="blue" title="No Transcript">
          Navigate to a YouTube video page to start chatting about the video content.
        </Alert>
      </Box>
    )
  }

  return (
    <Stack style={{ height: '100%', padding: 0 }} gap={0}>
      {/* Video Info Header */}
      {(videoInfo || transcript.metadata) && (
        <Box p="md" style={{ borderBottom: '1px solid #e0e0e0' }}>
          {transcript.metadata && (
            <>
              <Text size="sm" fw={600} lineClamp={2}>{transcript.metadata.title}</Text>
              <Text size="xs" c="dimmed" mt={2}>
                {transcript.metadata.channelName}
                {transcript.metadata.duration && ` â€¢ ${transcript.metadata.duration}`}
                {transcript.metadata.viewCount && ` â€¢ ${parseInt(transcript.metadata.viewCount).toLocaleString()} views`}
              </Text>
            </>
          )}
          {videoInfo && !transcript.metadata && (
            <Text size="sm" fw={600}>Video ID: {videoInfo.videoId}</Text>
          )}
          <Text size="xs" c="green" mt={4}>
            âœ“ Transcript loaded ({transcript.transcript.length} segments)
            {videoInfo?.language && ` â€¢ ${videoInfo.language}`}
            {videoInfo?.isAutoGenerated && ' â€¢ Auto-generated'}
          </Text>
        </Box>
      )}

      {/* Chat Messages */}
      <ScrollArea 
        ref={scrollAreaRef}
        style={{ flex: 1, padding: '1rem' }}
      >
        <Stack gap="md">
          {chatHistory.length === 0 && (
            <Box style={{ textAlign: 'center', padding: '2rem 1rem' }}>
              <Text size="lg" fw={600} mb="sm">ðŸ‘‹ Ready to chat!</Text>
              <Text size="sm" c="dimmed">
                Ask me anything about this video and I'll answer based on the transcript.
              </Text>
              <Text size="xs" c="dimmed" mt="sm">
                Try: "What is this video about?" or "Summarize the main points"
              </Text>
            </Box>
          )}

          {chatHistory.map((msg, index) => (
            <Paper
              key={index}
              p="md"
              style={{
                backgroundColor: msg.role === 'user' ? '#e3f2fd' : '#f5f5f5',
                alignSelf: msg.role === 'user' ? 'flex-end' : 'flex-start',
                maxWidth: '85%',
              }}
            >
              <Text size="xs" c="dimmed" mb={4}>
                {msg.role === 'user' ? 'You' : 'AI Assistant'}
              </Text>
              <Text size="sm" style={{ whiteSpace: 'pre-wrap' }}>
                {parseTimestampLinks(msg.content, videoInfo?.videoId || '')}
              </Text>
            </Paper>
          ))}

          {isProcessing && (
            <Paper
              p="md"
              style={{
                backgroundColor: '#f5f5f5',
                alignSelf: 'flex-start',
                maxWidth: '85%',
              }}
            >
              <Loader size="sm" />
            </Paper>
          )}
        </Stack>
      </ScrollArea>

      {/* Message Input */}
      <Box p="md" style={{ borderTop: '1px solid #e0e0e0' }}>
        <Stack gap="sm">
          <TextInput
            placeholder="Ask a question about the video..."
            value={question}
            onChange={(e) => setQuestion(e.target.value)}
            onKeyPress={handleKeyPress}
            disabled={isProcessing}
            rightSection={
              isProcessing ? <Loader size="xs" /> : null
            }
          />
          <Button
            onClick={handleSendMessage}
            disabled={!question.trim() || isProcessing}
            fullWidth
          >
            Send
          </Button>
        </Stack>
      </Box>
    </Stack>
  )
}

export default VideoChat

